---
title: "Analysis of Household Characteristics in the Jamuna River Basin"
author: "Prabhmeet Kaur"
date: "`r Sys.Date()`"
output: pdf_document
---

## Introduction
  
  In recent years, there has been a rise in cash transfer programs in the social protection space to vulnerable households impacted by extreme weather events.
  However, there is limited literature on optimal targeting interventions, revealing a critical need to explore the defining characteristics of households benefiting from these programs.

Given that most policymakers and researchers rely on registries to identify their beneficiaries, our project leverages a comprehensive census and baseline data covering 14 unions in the Jamuna River basin. This rich dataset provides an excellent opportunity to analyze and categorize household characteristics by grouping them based on shared attributes.

In this article, we will employ data mining techniques, specifically K-means clustering and Partitioning Around Medoids (PAM), to address the following key questions:
  
  - **Who are the most and least vulnerable households in this region?**
  - **What are the defining characteristics of these households?**
  
  Through these methods, we aim to deliver actionable insights into household segmentation in this geography.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#########################################################################################################
#Setting up
#########################################################################################################

rm(list=ls(all=TRUE))
# Get the username
username <- Sys.getenv("USERNAME")

# Get the user's operating system
os <- Sys.info()["sysname"]


if (os == "Windows") {
  username <- Sys.getenv("USERNAME")
} else if (os == "Darwin"){
  username <- Sys.getenv("USER")
}

# Set the working directory based on username (No Linux, add if someone has a Linux)
# Rocco and Hannah please modify your directories
if (os == "Windows" & username == "econ0683") {
  # Set the working directory for Windows users
  working_dir <- paste("C:/Users/", username,"/Dropbox/Bangladesh Flooding/Data Work/R_ML/", sep="")
}  else if (os == "Darwin" & username == "Prabhmeet") {
  # Set the working directory for macOS users
  working_dir <- paste("/Users/", username, "/Dropbox/Bangladesh Flooding/Data Work/R_ML/", sep="")
} else if (os == "Darwin" & username == "prabhmeetmatta") {
  # Set the working directory for macOS users
  working_dir <- paste("/Users/", username, "/Dropbox/Bangladesh Flooding/Data Work/R_ML/", sep="")
} else {
  # Set a default working directory if the operating system is not recognized
  setwd("~/my_project")
}

# Set the working directory
setwd(working_dir)


# Print the working directory
print(getwd())

# Load and install packages 
installation_needed  <- TRUE
loading_needed <- TRUE

list_packages= c("tidyverse", 'haven', 'lubridate', "tidyr", "dplyr", "ggplot2", "cluster", "factoextra", "readstata13", 'hopkins', 'kableExtra', 'knitr', 'caret', 'NbClust', 'psych', 'labelled')
# Remove the hash if you need to install
#if(installation_needed){install.packages(list_packages, repos='http://cran.us.r-project.org')}
if(loading_needed){lapply(list_packages, require, character.only = TRUE)}
```


```{r clean_data, include=FALSE}
#########################################################################################################
#Harmonising data to be numeric
#########################################################################################################

# Filter out columns with too many missing values (e.g. >20%)
data        <- read.dta13("data_for_ML.dta", convert.factors = TRUE, generate.factors=TRUE, nonint.factors = TRUE) # load data
#Clean data
source(file.path(working_dir, 'cleaning.R'))
```


##Data description
This exercise uses data collected from 14 districts during the census exercise in Bangladesh between April - July 2024. 


##Methodology

#Clustering tendency
We first use the Hopkins statistic to check if the data is clusterable.
The Hopkins statistic (Lawson and Jurs 1990) is used to assess the clustering tendency of a data set by measuring the probability that a given data set is generated by uniform data distribution.
We use a sample of about 20% of our census database for the analysis. As the Hopkins statistic is close to 1, this indicates that the data is highly clustered.

```{r cluster_tendency, echo=FALSE}
#########################################################################################################
#Checking for clustering tendency
#########################################################################################################

# Clustering tendency with hopkins
kable(describe(hh_filtered, fast = TRUE),format = 'html') %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

## Clustering Analysis
#The non-parametric analysis below using PAM and K-means: Partitioning Around Medoids to discover similarities between households in the baseline dataset. PAM instead of the go to K-means clustering is used, given the prior of the outliers and substantial variance in many variables of interests, e.g. income. 

### Silhouette Analysis for optimal clusters 
#Some optimality analysis for # of clusters: a.k.a. silhouette
#Give the size of the dataset, sample only 10% of these households
set.seed(42)
sample_pct = 0.2
hh_sampled <- hh_filtered %>% sample_frac(sample_pct)
# Remove rows with NA or Infinite values
hh_sampled <- hh_sampled[complete.cases(hh_sampled), ]
hh_sampled <- hh_sampled[!is.infinite(rowSums(hh_sampled)), ]
hh_sampled <- na.omit(hh_sampled)

# Checking for columns with near zero variance 
nzv <- nearZeroVar(hh_sampled) 
# Checking which columns did we remove
cols_sampled <- colnames(hh_sampled)
cols_hh_filtered <- colnames(hh_filtered)
col_diff <- setdiff(cols_hh_filtered, cols_sampled)

# Hopkins Statistic with nzv is NaN
hh_sampled <- hh_sampled[, -nzv] #removing these
h <- hopkins::hopkins(hh_sampled) # statistic =1 so from the documentation we know that the data is highly clustered (Calculated values 0-0.3 indicate regularly-spaced data. Values around 0.5 indicate random data. Values 0.7-1 indicate clustered data.)

# Plotting The Visual Assessment of cluster tendency (VAT) to visually determine if there are any potenial clusterings
factoextra::get_clust_tendency(data = hh_sampled, n = 10)
NbClust(hh_sampled, distance="euclidean", min.nc=2, max.nc=10, method="ward.D2", index="dindex") 
NbClust(hh_sampled, distance="manhattan", min.nc=2, max.nc=10, method="ward.D2", index="dindex") 
# In the plot of D index, a significant knee seems to be for 4 clusters. Therefore the optimal number of clusters according to D index is 4.

# Extract the best number of clusters from each run
optimal_clusters_dindex_euclidean <- nb_dindex_euclidean$Best.nc
optimal_clusters_dindex_manhattan <- nb_dindex_manhattan$Best.nc
optimal_clusters_hubert_euclidean <- nb_hubert_euclidean$Best.nc


# Summarize the results
results <- data.frame(
  Method = c("Dindex (Euclidean)", "Dindex (Manhattan)", "Hubert (Euclidean)"),
  Optimal_Clusters = c(optimal_clusters_dindex_euclidean, 
                       optimal_clusters_dindex_manhattan, 
                       optimal_clusters_hubert_euclidean)
)

# Display results
#print(results)

kable(n, format='html') %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Bar chart with optimal number of clusters
barplot(table(nb_best[,"Number_clusters"]),
        col=c("grey"), 
       main="Optimal number of clusters", 
      xlab="Number of clusters",
     ylab="Frequency among all indices")

fviz_nbclust(hh_sampled, pam, method ="silhouette")+theme_minimal() # 2
fviz_nbclust(hh_sampled, kmeans, method="silhouette")+theme_classic() # 2


### Clustering with PAM

hh_pam_results = pam(hh_sampled,
                     k = 2,
                     metric = "euclidean",
                     stand = FALSE)
fviz_cluster(hh_pam_results, 
             #palette = hh_pam_results$clustering,
             ellipse.type ="euclid",
             repel =TRUE,
             ggtheme =theme_minimal(),
             geom = "point")

km <- eclust(hh_sampled,FUNcluster="pam", k=2,hc_metric = "euclidean")
km.sil<-silhouette(km$cluster, dist(hh_sampled))
fviz_silhouette(km.sil)

km <- eclust(hh_sampled,FUNcluster="kmeans", k=2,hc_metric = "euclidean")
km.sil<-silhouette(km$cluster, dist(hh_sampled))
fviz_silhouette(km.sil)

hh_sampled.c<-cbind(hh_sampled, km$cluster)
colnames(hh_sampled.c)[-1]<-c("Group")

df.m <- melt(hh_sampled.c, id.var = "Group")
df.m$Group <- as.character(df.m$Group)

# Define the variables you want to include in your plot
variables_to_plot <- c("FCS", "stair_numeric", "land_own", "monthly_income", "count_assets_durable", "ppi")  

# Filter the melted data frame to include only these variables
df.m <- df.m %>% filter(variable %in% variables_to_plot)


p <- ggplot(data = df.m, aes(x=variable, y=value)) +
  geom_boxplot(aes(fill = Group),outlier.size = 1) +
  facet_wrap( ~ variable, scales="free", ncol = 2) +
  xlab(label = NULL) + ylab(label = NULL) + ggtitle("Boxplots for 2 Groups of Households") +
  guides(fill=guide_legend(title="Groups"))

p 

GroupsSummary <- describeBy(hh_sampled.c[,1:-1], hh_sampled.c[,'Group'])

kable(GroupsSummary[[1]], format = "html", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))


kable(GroupsSummary[[2]], format = "html", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```
